{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('post_election_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14268 120\n",
      "0.8083333333333333\n",
      "Most Informative Features\n",
      "                     que = True              gen : neg    =    202.0 : 1.0\n",
      "                      la = True              gen : neg    =    198.9 : 1.0\n",
      "                      de = True              gen : neg    =    193.0 : 1.0\n",
      "                     los = True              gen : neg    =    157.1 : 1.0\n",
      "                      un = True              gen : neg    =    149.2 : 1.0\n",
      "                     con = True              gen : neg    =    104.3 : 1.0\n",
      "                      se = True              gen : neg    =    100.6 : 1.0\n",
      "               uncertain = True              gen : pos    =     69.4 : 1.0\n",
      "                  switch = True              gen : pos    =     63.9 : 1.0\n",
      "                      du = True              pos : neg    =     62.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_pos = df1[df1['predictor']=='pos'].reset_index()\n",
    "df_neg = df1[df1['predictor']=='neg'].reset_index()\n",
    "df_gen = df1[df1['predictor']=='gen'].reset_index()\n",
    "\n",
    "pos_string = df_pos['text']\n",
    "neg_string = df_neg['text']\n",
    "gen_string = df_gen['text']\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "## Importing stopwords \n",
    "from nltk.corpus import stopwords \n",
    "stopwords_english = stopwords.words('english')\n",
    " \n",
    "## Importing porter stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "## Importing the tokenizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def clean_tweets(tweet):\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "    ## Cleaing up RTs\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    \n",
    "    ## Removing hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    ## Removing hastags\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    " \n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    " \n",
    "    tweets_clean = []    \n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and # remove stopwords\n",
    "                word not in string.punctuation): # remove punctuation\n",
    "            ##stem_word = stemmer.stem(word) # stemming word\n",
    "            tweets_clean.append(word)\n",
    " \n",
    "    return tweets_clean\n",
    "\n",
    "def bag_of_words(tweet):\n",
    "    words = clean_tweets(tweet)\n",
    "    words_dictionary = dict([word, True] for word in words)    \n",
    "    return words_dictionary\n",
    " \n",
    "# positive tweets feature set\n",
    "pos_tweets_set = []\n",
    "for tweet in pos_string:\n",
    "    pos_tweets_set.append((bag_of_words(tweet), 'pos'))    \n",
    "    \n",
    "## negative tweets\n",
    "neg_tweets_set = []\n",
    "for tweet in neg_string:\n",
    "    neg_tweets_set.append((bag_of_words(tweet), 'neg'))\n",
    "    \n",
    "## general tweets\n",
    "\n",
    "gen_tweets_set = []\n",
    "for tweet in gen_string:\n",
    "    gen_tweets_set.append((bag_of_words(tweet), 'gen'))\n",
    "    \n",
    "from random import shuffle \n",
    "shuffle(pos_tweets_set)\n",
    "shuffle(neg_tweets_set)\n",
    " \n",
    "test_set = pos_tweets_set[:40] + neg_tweets_set[:40] + gen_tweets_set[:40]\n",
    "train_set = pos_tweets_set[10:] + neg_tweets_set[10:] + gen_tweets_set[10:]\n",
    "print(len(train_set),len(test_set))\n",
    "\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    " \n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "print(accuracy) # Output: 0.765\n",
    " \n",
    "print (classifier.show_most_informative_features(10))\n",
    "\n",
    "candidates_full_name = ['Joe Biden', 'Amy Klobuchar', 'Pete Buttigieg', 'Bloomberg', 'Bernie Sanders', 'Elizabeth Warren']\n",
    "candidates_last_name = ['Biden', 'Klobuchar', 'Buttigieg', 'Bloomberg', 'Sanders', 'Warren']\n",
    "\n",
    "def get_sentiment(name):\n",
    "    \n",
    "    final_results = []\n",
    "    \n",
    "    for potential_pres in name:\n",
    "        custom_tweet_set = bag_of_words(potential_pres)\n",
    "        prob_result = classifier.prob_classify(custom_tweet_set)\n",
    "        name = potential_pres\n",
    "        results = str(prob_result.max()) \n",
    "        neg_results = str(prob_result.prob(\"neg\"))\n",
    "        pos_results = str(prob_result.prob(\"pos\"))\n",
    "        create_dict = {'Name': name, 'Results': results, 'Negative Probability': neg_results, 'Positive Probability': pos_results}\n",
    "        final_results.append(create_dict)\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_elect_sent = get_sentiment(candidates_last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_elec_df = pd.DataFrame(post_elect_sent)\n",
    "\n",
    "post_elec_df['scenario'] = 'post_election'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_elec_df.to_csv('post_election_candidate_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
